---
apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: localai-app
  namespace: localai
spec:
  interval: 30m
  chart:
    spec:
      chart: local-ai
      version: 2.1.2
      sourceRef:
        kind: HelmRepository
        name: go-skynet
        namespace: flux-system
  maxHistory: 2
  install:
    remediation:
      retries: 3
  upgrade:
    cleanupOnFail: true
    remediation:
      retries: 3
  uninstall:
    keepHistory: false
  values:
    deployment:
      env:
        REBUILD: false
        CMAKE_ARGS: "-DLLAMA_AVX512=OFF"
    promptTemplates:
      ggml-gpt4all-j.tmpl: |
        The prompt below is a question to answer, a task to complete, or a conversation to respond to; decide which and write an appropriate response.
        ### Prompt:
        {{.Input}}
        ### Response:
    models:
      list:
        - url: "https://gpt4all.io/models/ggml-gpt4all-j.bin"
      persistence:
        pvc:
          enabled: true
          size: 30Gi
          accessModes:
            - ReadWriteOnce
          annotations: {}
          # Optional
          storageClass: home-cluster-nfs-1

        hostPath:
          enabled: true
          path: "/models"

    ingress:
      enabled: true
      className: "external"
      annotations:
        external-dns.alpha.kubernetes.io/target: "external.${SECRET_DOMAIN}"
      hosts:
        - host: &host "local-ai.${SECRET_DOMAIN}"
          paths:
            - path: /
              pathType: ImplementationSpecific
      # tls: []
      #  - secretName: chart-example-tls
      #    hosts:
      #      - chart-example.local
